{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first operation in Python is to import the libraries one will be working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chaospy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken the file Carlos provided me and made a few adjustments, most of which are minor ones, i.e. plainly format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have also: i) Edited the iTFA intake as gamma-shape distributions;\n",
    "            ii) Considered their min, max in the range (0, 5) % daily energy int.\n",
    "           iii) Furthermore distributions for the Relative risk of a 2% E iTFA intake has been considered as well (truncated normal), probability of 2nd CHD attack (1,2) (truncated gamma) and inflation rate (0,7) (truncated normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuele\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/Samuele/Dropbox/ECGC_Barcelona/1.Projects/02-JRC/Work/iTFA/Parameters_distributions.xlsx')\n",
    "df2 = df.sort_values(['Shape'], ascending = True)\n",
    "df3 = df2[df2.columns[0:7]]\n",
    "df4 = df3.reset_index()\n",
    "del df4['index']\n",
    "df4.loc[25]=['Inflation rate', '%', 'normal', 0, 7, 3.5, 3.5]\n",
    "df4.loc[26]=['Probability of 2nd CHD attack', '', 'lognormal', 1, 2, 1.5, 1.5]\n",
    "df4.loc[27]=['Relative Risk', '', 'normal', 1.11, 1.37, 1.23, (1.37-1.11)/1.96]\n",
    "df4['Shape'].loc[21:24]='gamma'\n",
    "df4['Min'].loc[21:24]=0\n",
    "df4['Max'].loc[21:24]=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow methodology builds on the logic to take out each distribution-shape typology and progressively narrow down the selection. Eventually, the dataframes generated are merged into a final one. Let's start by tackling the easiest case, the uniform distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unif = []\n",
    "df5 = pd.DataFrame()\n",
    "sample = []\n",
    "if df4['Shape'].any()=='Uniform':\n",
    "    for i1 in df4['Variable'].loc[df4['Shape'] == 'Uniform'].index:\n",
    "        dist=cp.Uniform(df4['Min'].loc[df4['Shape'] == 'Uniform'][i1],df4['Max'].loc[df4['Shape'] == 'Uniform'][i1])\n",
    "        unif.append(dist)\n",
    "        unifS=unif[i1].sample(1000, rule=\"S\")\n",
    "        np.random.shuffle(unifS)\n",
    "        sample.append(unifS)\n",
    "        df5 = pd.DataFrame(sample, index=df4['Variable'].loc[df4['Shape'] == 'Uniform'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, it's time for the truncated normal and the lognormal and eventually the gammas. As regards the latter, the missing-value figures for the (min,max) are filled with (0, 1e99) for the sake of praticality. Just a brief comment about the truncation I eventually developed, it can be implemented by putting in place a nested command, i.e. (cp for chaospy) cp.trunc(cp.gamma(...),...) that assures the distribution is generated within a lower and upper threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The database is then readjusted and the distributions of different shape are also built \n",
    "df6=df4.loc[2:]\n",
    "df7 = df6.sort_values(['Shape'], ascending = False)\n",
    "df8 = df7.reset_index()\n",
    "del df8['index']\n",
    "normal = []\n",
    "sampleN = []\n",
    "if df8['Shape'].any()=='normal':\n",
    "    for i2 in df8['Variable'].loc[df8['Shape'] == 'normal'].index:\n",
    "        distN=cp.Truncnorm(df8['Min'].loc[df8['Shape'] == 'normal'][i2],df8['Max'].loc[df8['Shape'] == 'normal'][i2],\\\n",
    "        df8['Mean'].loc[df8['Shape'] == 'normal'][i2], df8['Std'].loc[df8['Shape'] == 'normal'][i2])                   \n",
    "        normal.append(distN)\n",
    "        normalS=normal[i2].sample(1000, rule=\"S\")\n",
    "        np.random.shuffle(normalS)\n",
    "        sampleN.append(normalS)\n",
    "df9 = pd.DataFrame(sampleN, index=df8['Variable'].loc[df8['Shape'] == 'normal'].values)\n",
    "\n",
    "df8b=df8.loc[2:].reset_index()\n",
    "del df8b['index']\n",
    "df8c = df8b\n",
    "lognormal = []\n",
    "sampleL = []\n",
    "if df8b['Shape'].any()=='lognormal':\n",
    "    for i2b in df8c['Variable'].loc[df8c['Shape'] == 'lognormal'].index:\n",
    "        distL=cp.trunk(cp.Lognormal(df8c['Mean'].loc[df8c['Shape'] == 'lognormal'][i2b],df8c['Std'].loc[df8c['Shape'] == 'lognormal'][i2b],0),\\\n",
    "        df8c['Max'].loc[df8c['Shape'] == 'lognormal'][i2b])        \n",
    "        lognormal.append(distL)\n",
    "        lognormalS=lognormal[i2b].sample(1000, rule=\"S\")\n",
    "        np.random.shuffle(lognormalS)\n",
    "        sampleL.append(lognormalS)\n",
    "df9b = pd.DataFrame(sampleL, index=df8c['Variable'].loc[df8c['Shape'] == 'lognormal'].values)\n",
    "\n",
    "df11=df8.loc[4:]\n",
    "df13 = df11.sort_values(['Shape'], ascending = False)\n",
    "df13 = df11.reset_index()\n",
    "del df13['index']\n",
    "df13a = df13\n",
    "gamma = []\n",
    "sampleG = []\n",
    "if df13['Shape'].any()=='gamma':\n",
    "    df13a['Max']=df13['Max'].loc[df13['Shape'] == 'gamma'].fillna(1e99)\n",
    "    df13a['Min']=df13['Min'].loc[df13['Shape'] == 'gamma'].fillna(0)    \n",
    "    for i3 in df13a['Variable'].loc[df13a['Shape'] == 'gamma'].index:\n",
    "        distG=cp.trunk(cp.Gamma((df13a['Mean']**2/df13a['Std']**2).loc[df13a['Shape'] == 'gamma'][i3],(df13a['Std']**2/df13a['Mean']).loc[df13a['Shape'] == 'gamma'][i3],\\\n",
    "        df13a['Min'].loc[df13a['Shape'] == 'gamma'][i3]),df13a['Max'].loc[df13a['Shape'] == 'gamma'][i3])\n",
    "        gamma.append(distG)\n",
    "        gammaS=gamma[i3].sample(1000, rule=\"S\")\n",
    "        np.random.shuffle(gammaS)\n",
    "        sampleG.append(gammaS)\n",
    "df16 = pd.DataFrame(sampleG, index=df13a['Variable'].loc[df13a['Shape'] == 'gamma'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By concatenating the four dataframes generated, it is possible to have a final one ready for delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfF = pd.concat([df5, df9, df9b, df16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost ready for delivery, it is better transposing the dataframe in order to have a column-based variable representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfFi = dfF.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to export the data to an excel file ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfFi.to_excel('C:/Users/Samuele/Dropbox/ECGC_Barcelona/1.Projects/02-JRC/Work/iTFA/gamma_intake_1000.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
